{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Descriptive statistics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics"
      ],
      "metadata": {
        "id": "eNcHCHjlgCG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code describes the dataset used in the sentiment analysis"
      ],
      "metadata": {
        "id": "NH3uokrRgD97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slKxsYyGa1wQ",
        "outputId": "8ed195c9-0963-425b-e134-8693208d91ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "         Year  Observations Earliest Observation Latest Observation  Mean Word Count  Company Count\n",
            "0        2009           112           2009-06-26         2009-12-31       785.258929             71\n",
            "1        2010          2836           2010-01-01         2010-12-31       409.405853            893\n",
            "2        2011          4331           2011-01-01         2011-12-30       429.110136           1039\n",
            "3        2012         10462           2012-01-03         2012-12-31       311.993118           2379\n",
            "4        2013         13480           2013-01-01         2013-12-31       259.331009           3210\n",
            "5        2014         26715           2014-01-01         2014-12-31       275.459330           4188\n",
            "6        2015         36496           2015-01-01         2015-12-31       319.269454           4973\n",
            "7        2016         37777           2016-01-01         2016-12-31       364.352490           5029\n",
            "8        2017         40828           2017-01-01         2017-12-31       476.309077           5016\n",
            "9        2018         80062           2018-01-01         2018-12-31       664.175639           6318\n",
            "10       2019         67782           2019-01-01         2019-08-28      1200.693016           5610\n",
            "11  All years        320881           2009-06-26         2019-08-28       612.843400           9546\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pysentiment2 as ps\n",
        "from google.colab import drive \n",
        "import numpy as np\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"gdrive/My Drive/Thesis/processed data/data_processed.csv\")\n",
        "\n",
        "#Prepare data for descriptive statistics\n",
        "data[\"Date\"] = pd.to_datetime(data[\"Date\"], format = \"%Y-%m-%d\")\n",
        "data.sort_values(by= \"Date\", inplace = True)\n",
        "data.drop_duplicates(inplace = True)\n",
        "\n",
        "#Function to split initial dataframe into dataframes grouped by year\n",
        "def split_years(dt):\n",
        "    dt['year'] = dt['Date'].dt.year\n",
        "    return [dt[dt['year'] == y] for y in dt['year'].unique()]\n",
        "\n",
        "data_splt_years = split_years(data)\n",
        "data_fill = []\n",
        "\n",
        "for df_year_splt in data_splt_years:\n",
        "    year = df_year_splt[\"Date\"].iloc[0].year\n",
        "    obs_count = len(df_year_splt)\n",
        "    earliest_obs = df_year_splt[\"Date\"].iloc[0]\n",
        "    latest_obs = df_year_splt[\"Date\"].iloc[-1]\n",
        "    mean_word_count = df_year_splt[\"Word_count\"].mean()\n",
        "    company_count = df_year_splt[\"Ticker\"].nunique()\n",
        "\n",
        "    data_fill.append([year, obs_count, earliest_obs, latest_obs, mean_word_count, company_count])\n",
        "\n",
        "#Calculate the metrics for the whole dataset\n",
        "obs_count = len(data)\n",
        "earliest_obs = data[\"Date\"].iloc[0]\n",
        "latest_obs = data[\"Date\"].iloc[-1]\n",
        "mean_word_count = data[\"Word_count\"].mean()\n",
        "company_count = data[\"Ticker\"].nunique()\n",
        "\n",
        "data_fill.append([\"All years\", obs_count, earliest_obs, latest_obs, mean_word_count, company_count])\n",
        "\n",
        "df_by_year = pd.DataFrame(data_fill ,columns = [\"Year\", \"Observations\", \"Earliest Observation\", \"Latest Observation\", \"Mean Word Count\", \"Company Count\"])\n",
        "\n",
        "print(df_by_year)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, we check the sentiment indices of the dataset given by the dictionary methods using the Harvard Psychsosocological Dictionary and the Loughran and McDonald Dictionary."
      ],
      "metadata": {
        "id": "2S1gZ0SXDY_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_fill = []\n",
        "\n",
        "hiv4 = ps.HIV4()\n",
        "lm = ps.LM()\n",
        "\n",
        "data_fill = []\n",
        "\n",
        "for df_year_splt in data_splt_years:\n",
        "\n",
        "    year = df_year_splt[\"Date\"].iloc[0].year\n",
        "\n",
        "    hiv4_pos = []\n",
        "    hiv4_neg = []\n",
        "    hiv4_tone = []\n",
        "\n",
        "    lm_pos = []\n",
        "    lm_neg = []\n",
        "    lm_tone = []\n",
        "\n",
        "    for index, row in df_year_splt.iterrows():\n",
        "        print(row[\"Ticker\"])\n",
        "        tokens_hiv4 = hiv4.tokenize(row[\"Text\"])\n",
        "        tokens_lm = lm.tokenize(row[\"Text\"])\n",
        "\n",
        "        score_hiv4 = hiv4.get_score(tokens_hiv4)\n",
        "        score_lm = lm.get_score(tokens_lm)\n",
        "\n",
        "        hiv4_pos.append(score_hiv4[\"Positive\"])\n",
        "        hiv4_neg.append(score_hiv4[\"Negative\"])\n",
        "        hiv4_tone.append(score_hiv4[\"Positive\"] - score_hiv4[\"Negative\"])\n",
        "\n",
        "        lm_pos.append(score_lm[\"Positive\"])\n",
        "        lm_neg.append(score_lm[\"Negative\"])\n",
        "        lm_tone.append(score_lm[\"Positive\"] - score_lm[\"Negative\"])\n",
        "\n",
        "    data_fill.append([year, sum(hiv4_pos), sum(hiv4_neg), sum(hiv4_tone), sum(lm_pos), sum(lm_neg), sum(lm_tone)])\n",
        "\n",
        "df_by_year_dm = pd.DataFrame(data_fill ,columns = [\"Year\", \"HIV4 positive\", \"HIV4 negative\", \"HIV4 tone\", \"LM_pos\", \"LM_neg\", \"LM_tone\"])\n",
        "\n",
        "print(df_by_year_dm)\n"
      ],
      "metadata": {
        "id": "RBxWA_49A10m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}