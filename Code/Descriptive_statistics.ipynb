{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNcHCHjlgCG4"
      },
      "source": [
        "# Descriptive statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH3uokrRgD97"
      },
      "source": [
        "The following code describes the dataset used in the sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "!pip install pysentiment2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms-_xC3b_zSD",
        "outputId": "59ce430a-bb35-4426-8473-34e85e3fb343"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Collecting pysentiment2\n",
            "  Downloading pysentiment2-0.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (1.3.5)\n",
            "Requirement already satisfied: nltk>=2.0 in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=2.0->pysentiment2) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2022.1)\n",
            "Installing collected packages: pysentiment2\n",
            "Successfully installed pysentiment2-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slKxsYyGa1wQ",
        "outputId": "862db2cb-0509-43cd-9839-bd1538e752d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "+----+-----------+-----------------+-------------------+-----------------+\n",
            "|    | Year      |   News Articles |   Mean Word Count |   Company Count |\n",
            "|----+-----------+-----------------+-------------------+-----------------|\n",
            "|  0 | 2009      |             111 |               783 |              70 |\n",
            "|  1 | 2010      |            2791 |               404 |             865 |\n",
            "|  2 | 2011      |            4277 |               426 |            1001 |\n",
            "|  3 | 2012      |           10259 |               311 |            2279 |\n",
            "|  4 | 2013      |           13143 |               257 |            3076 |\n",
            "|  5 | 2014      |           26234 |               274 |            3997 |\n",
            "|  6 | 2015      |           35457 |               319 |            4312 |\n",
            "|  7 | 2016      |           36569 |               365 |            4261 |\n",
            "|  8 | 2017      |           39629 |               477 |            4188 |\n",
            "|  9 | 2018      |           77086 |               669 |            5195 |\n",
            "| 10 | 2019      |           66118 |              1215 |            4839 |\n",
            "| 11 | All years |          311674 |               617 |            6926 |\n",
            "+----+-----------+-----------------+-------------------+-----------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pysentiment2 as ps\n",
        "from google.colab import drive \n",
        "from tabulate import tabulate\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"gdrive/My Drive/Thesis/processed data/processdata_woSWandPS.csv\")\n",
        "\n",
        "#Prepare data for descriptive statistics\n",
        "data[\"Date\"] = pd.to_datetime(data[\"Date\"], format = \"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "#Function to split initial dataframe into dataframes grouped by year\n",
        "def split_years(dt):\n",
        "    dt[\"Year\"] = dt[\"Date\"].dt.year\n",
        "    return [dt[dt[\"Year\"] == y] for y in dt[\"Year\"].unique()]\n",
        "\n",
        "data_splt_years = split_years(data)\n",
        "data_fill = []\n",
        "\n",
        "for df_year_splt in data_splt_years:\n",
        "    year = df_year_splt[\"Date\"].iloc[0].year\n",
        "    obs_count = len(df_year_splt)\n",
        "    mean_word_count = round(df_year_splt[\"Word Count\"].mean(),0)\n",
        "    company_count = df_year_splt[\"Ticker\"].nunique()\n",
        "\n",
        "    data_fill.append([year, obs_count, mean_word_count, company_count])\n",
        "\n",
        "#Calculate the metrics for the whole dataset\n",
        "obs_count = len(data)\n",
        "mean_word_count = round(data[\"Word Count\"].mean(),0)\n",
        "company_count = data[\"Ticker\"].nunique()\n",
        "\n",
        "data_fill.append([\"All years\", obs_count, mean_word_count, company_count])\n",
        "\n",
        "df_by_year = pd.DataFrame(data_fill ,columns = [\"Year\", \"News Articles\", \"Mean Word Count\", \"Company Count\"])\n",
        "\n",
        "print(tabulate(df_by_year, headers = \"keys\", tablefmt = \"psql\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get top 120 companies with regards to news frequency (later only top 100, since some will be removed like SPX)\n",
        "\n",
        "yearst = [2015, 2016, 2017, 2018, 2019]\n",
        "\n",
        "data = data[data.Year.isin(yearst) == True]\n",
        "unique_data_company =  data.groupby(\"Ticker\").nunique()\n",
        "\n",
        "unique_data_company.sort_values(by = \"Text\", ascending = False, inplace = True)\n",
        "\n",
        "print(list(unique_data_company.index[0:120]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKW4Dy__flLn",
        "outputId": "74ff20f4-fafd-4c87-8159-73497d8064e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'AMZN', 'TSLA', 'FB', 'BA', 'NFLX', 'DIS', 'EFX', 'SPX', 'BAC', 'INTC', 'DAX', 'F', 'GLD', 'GE', 'GM', 'MSFT', 'SBUX', 'AIR', 'AAL', 'IBM', 'JPM', 'CMG', 'WFC', 'C', 'TWTR', 'WMT', 'MCD', 'AMD', 'NVDA', 'JNJ', 'GS', 'BABA', 'CAT', 'MU', 'CSCO', 'XOM', 'CVX', 'BP', 'GOOGL', 'USD', 'GPRO', 'COST', 'HD', 'QQQ', 'SQ', 'NKE', 'KO', 'AXP', 'TGT', 'ATVI', 'CMCSA', 'SNAP', 'DAL', 'LMT', 'T', 'ABBV', 'PFE', 'GILD', 'ADBE', 'CRM', 'VZ', 'AVGO', 'BX', 'LULU', 'BLK', 'UNH', 'FIT', 'KMI', 'BBY', 'PG', 'AGI', 'AA', 'AMAT', 'MRK', 'M', 'BIDU', 'QCOM', 'JCP', 'FDX', 'AMGN', 'BMY', 'ORCL', 'BHP', 'PYPL', 'MA', 'FRA', 'KR', 'SHOP', 'MO', 'GME', 'PM', 'VRX', 'CHK', 'ABX', 'MMM', 'BBBY', 'COP', 'UTX', 'IRBT', 'MS', 'SPY', 'FCX', 'HAL', 'AGN', 'HPQ', 'UAL', 'CELG', 'JWN', 'CVS', 'V', 'EA', 'STZ', 'GLW', 'ADP', 'APC', 'AZN', 'EBAY', 'ACN', 'PEP']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Descriptive statistics.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}